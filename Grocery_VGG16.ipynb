{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This block is used for uploading the api key associated with my account\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "bll6sbfMWh-k",
        "outputId": "a5c7c2b4-50f8-4eb2-ed80-91a2ae252fb9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3f77d932-5d46-48b9-bbfb-24ae8d2b9e6e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3f77d932-5d46-48b9-bbfb-24ae8d2b9e6e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 76 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Brought this from the kaggle page\n",
        "\n",
        "!kaggle datasets download -d amoghmisra27/grocery"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qijx4HR1-cFj",
        "outputId": "a5e0bc6b-3fcb-406f-9d77-1048f1805c78"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grocery.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "#Extracting the dataset contents\n",
        "zipFilePath='/content/grocery.zip'\n",
        "zipFileObj=ZipFile(file=zipFilePath)\n",
        "zipFileObj.extractall('/tmp/dataset')\n"
      ],
      "metadata": {
        "id": "szoHSHkl_nS4"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_path='/tmp/dataset/GroceryStoreDataset-master/dataset/test'\n",
        "\n",
        "\n",
        "train_path='/tmp/dataset/GroceryStoreDataset-master/dataset/train'"
      ],
      "metadata": {
        "id": "xOE4J746Ikwz"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "6gX53YEODDLc"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Lambda, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = [224, 224]"
      ],
      "metadata": {
        "id": "gVHsYBaBKFyL"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YDK_uHArU5hS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f746bb9e-476d-41d0-c85b-bfa09006fadb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3xQDmfTY-QO",
        "outputId": "d931706b-0486-42fc-f223-6a08a19f1f3e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Give dataset path\n",
        "train_path = '/content/drive/MyDrive/Colab Notebooks/thesis 400/GroceryStoreDataset-master/dataset/train'\n",
        "test_path = '/content/drive/MyDrive/Colab Notebooks/thesis 400/GroceryStoreDataset-master/dataset/test'"
      ],
      "metadata": {
        "id": "rBXQSPgEZAqn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Only to show the content nothing else\n",
        "from PIL import Image \n",
        "import os \n",
        "from IPython.display import display\n",
        "from IPython.display import Image as _Imgdis\n",
        "# creating a object  \n",
        "\n",
        "  \n",
        "folder = train_path+'/Fruit/Apple/Golden-Delicious'\n",
        "\n",
        "\n",
        "apple_train = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
        "print(\"Working with {0} images\".format(len(apple_train)))\n",
        "print(\"Image examples: \")\n",
        "\n",
        "x = len(apple_train)\n",
        "for i in range(x):\n",
        "    print(apple_train[i])\n",
        "    display(_Imgdis(filename=folder + \"/\" + apple_train[i], width=240, height=240))"
      ],
      "metadata": {
        "id": "COG1pFnAZd0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ],
      "metadata": {
        "id": "qfAlxaM2gFTC"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg.input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eqACZHPvF6m",
        "outputId": "0dc36545-38dd-4e08-92cb-c05bb3b590a3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 224, 224, 3) dtype=float32 (created by layer 'input_3')>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "YMXQsed2z3Fe"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folders = glob('/tmp/dataset/GroceryStoreDataset-master/dataset/train')\n",
        "print(len(folders))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dg_765Rz5Rc",
        "outputId": "c8258418-91e5-49a5-c674-cf6f9c90e2c2"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = Flatten()(vgg.output)\n",
        "prediction = Dense(len(folders), activation='relu')(x)\n",
        "model = Model(inputs=vgg.input, outputs=prediction)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "50Wzrqsdz6-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf \n",
        "from keras import optimizers\n",
        "\n",
        "\n",
        "adam = tf.keras.optimizers.Adam()\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "G-ODS6epz8Wb"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')"
      ],
      "metadata": {
        "id": "NlfSU4k0PMZj"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')"
      ],
      "metadata": {
        "id": "iYPImRHoWb-8"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_set = train_datagen.flow_from_directory(train_path,\n",
        "                                              target_size = (224, 224),\n",
        "                                              batch_size = 32,\n",
        "                                              class_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS0YUWhLWerq",
        "outputId": "24ae5d90-9ff0-49e0-c257-84bc5c98e046"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2640 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = test_datagen.flow_from_directory(test_path,\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLzFp95mWmt7",
        "outputId": "659b68b9-e6b5-4895-e64a-cf3ca06e7316"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2485 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='Gmodel1', \n",
        "                               verbose=2, save_best_only=True)\n",
        "\n",
        "callback = [checkpoint]\n",
        "\n",
        "start = datetime.now()\n",
        "model_history = model.fit(\n",
        "  x= train_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=20,\n",
        "  steps_per_epoch=10,\n",
        "  validation_steps=32, callbacks=callback,verbose=2)\n",
        "\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQelvyQ2eKTv",
        "outputId": "7518ebb9-629b-400b-dee9-b540af7e245d"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 5.14165, saving model to Gmodel1\n",
            "10/10 - 20s - loss: 5.2394 - accuracy: 0.6583 - val_loss: 5.1416 - val_accuracy: 0.6667 - 20s/epoch - 2s/step\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 2: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 3: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 4: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 5: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 6: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 7: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 8: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 9: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 10: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 11: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 12: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 13: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 14: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 15: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 16: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 17: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 18: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 19: val_loss did not improve from 5.14165\n",
            "10/10 - 17s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 17s/epoch - 2s/step\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 20: val_loss did not improve from 5.14165\n",
            "10/10 - 18s - loss: 5.1417 - accuracy: 0.6667 - val_loss: 5.1416 - val_accuracy: 0.6667 - 18s/epoch - 2s/step\n",
            "Training completed in time:  0:06:24.308590\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(model_history.history['accuracy'])\n",
        "plt.plot(model_history.history['val_accuracy'])\n",
        "plt.title('CNN Model accuracy values')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "zAO4tdTL9K_i",
        "outputId": "68e7f062-39b6-468d-e2b5-12229731f2cc"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath='Gmodel1', \n",
        "                               verbose=2, save_best_only=True)\n",
        "\n",
        "callback = [checkpoint]\n",
        "\n",
        "start = datetime.now()\n",
        "model.fit(train_set,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          validation_data=test_set)\n",
        "\n",
        "duration = datetime.now() - start\n",
        "print(\"Training completed in time: \", duration)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-uUGNMqfWp9w",
        "outputId": "1dd92caa-fa35-4b25-dfeb-b7435bfd9230"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-cf70a2e8fa37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m           validation_data=test_set)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'Adam/Adam/update_1/ResourceApplyAdam' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1233, in inner\n      self.run()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1147, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n      user_expressions, allow_stdin,\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-48-d953d07a8f90>\", line 17, in <module>\n      validation_steps=32)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 863, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 532, in minimize\n      return self.apply_gradients(grads_and_vars, name=name)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 675, in apply_gradients\n      name=name)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 717, in _distributed_apply\n      var, apply_grad_to_update_var, args=(grad,), group=False)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 699, in apply_grad_to_update_var\n      update_op = self._resource_apply_dense(grad, var, **apply_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py\", line 176, in _resource_apply_dense\n      use_locking=self._use_locking)\nNode: 'Adam/Adam/update_1/ResourceApplyAdam'\nvar and grad do not have the same shape[1] [3]\n\t [[{{node Adam/Adam/update_1/ResourceApplyAdam}}]] [Op:__inference_train_function_6481]"
          ]
        }
      ]
    }
  ]
}